{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf52b562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  7, 15, 16, 17, 19, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4,7,15,16,17,19,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb11994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas\n",
    "import math\n",
    "from generate_inputs import TrajectoryDataset\n",
    "from generate_inputs import device\n",
    "from generate_inputs import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d350d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "15\n",
      "16\n",
      "17\n",
      "19\n",
      "20\n",
      "79664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = TrajectoryDataset('./data/', np.array([1,2,3,4,7,15,16,17,19,20]) , 50, 0.5, math.radians(10))\n",
    "print(len(train_dataset))\n",
    "train_dataset[0]['image2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d400565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([])\n",
      "(1, 2, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Verifying input dimensions\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "\n",
    "input = torch.randn(1, 2, 224, 224).to(device)\n",
    "out = net(input)\n",
    "print(out.shape)\n",
    "\n",
    "x = np.stack([train_dataset[0]['image1'], train_dataset[0]['image2']])\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8aa064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.36631198291796746\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.03342584988960675\n",
      "Test loss: 0.01736367372123152\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.015423840432477085\n",
      "Test loss: 0.013642552763790403\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.012527026711385291\n",
      "Test loss: 0.01075067838451326\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.011179554061966053\n",
      "Test loss: 0.011217079027612289\n",
      "Train loss: 0.010151157775106938\n",
      "Test loss: 0.009977896795610149\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.009430312635643158\n",
      "Test loss: 0.009140492590288186\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.008794492876977237\n",
      "Test loss: 0.009097502604283584\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.008293987746055848\n",
      "Test loss: 0.009685200128311743\n",
      "Train loss: 0.007836481717686042\n",
      "Test loss: 0.00838356139947907\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.007483578891063471\n"
     ]
    }
   ],
   "source": [
    "# Training X- network\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "idxs = list(range(len(train_dataset)))\n",
    "random.shuffle(idxs)\n",
    "net_x = Net()\n",
    "net_x = net_x.to(device)\n",
    "optimizer = optim.Adam(net_x.parameters(), lr=0.0001)\n",
    "train_idxs = idxs[:int(len(train_dataset) * 0.8)]\n",
    "test_idxs = idxs[int(len(train_dataset) * 0.8):]\n",
    "min_loss = 1\n",
    "for epoch in range(10):\n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    for idx in test_idxs:\n",
    "        x = np.stack([train_dataset[idx]['image1'], train_dataset[idx]['image2']])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().to(device)\n",
    "        out = net_x(x)\n",
    "        target = torch.tensor(train_dataset[idx]['rel_pose'][0]).float().to(device)\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        test_total += loss.item()\n",
    "    print(\"Test loss:\", test_total / len(test_idxs))\n",
    "    if min_loss > test_total / len(test_idxs):\n",
    "        print(\"New lowest test loss, saved!\")\n",
    "        torch.save(net_x, \"net_x_5.pyt\")\n",
    "        min_loss = test_total / len(test_idxs)\n",
    "    \n",
    "    for idx in train_idxs:\n",
    "        x = np.stack([train_dataset[idx]['image1'], train_dataset[idx]['image2']])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().to(device)\n",
    "        out = net_x(x)\n",
    "        target = torch.tensor(train_dataset[idx]['rel_pose'][0]).float().to(device)\n",
    "        #print(out.shape, target.shape)\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_total += loss.item()\n",
    "        optimizer.step()     \n",
    "    print(\"Train loss:\", train_total / len(train_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf90104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.14075488200823758\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.003021571555673016\n",
      "Test loss: 0.0017899226720818346\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0013904040873345624\n",
      "Test loss: 0.0009817894780056598\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0010807394361874686\n",
      "Test loss: 0.0008168966435165492\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0009085131168910843\n",
      "Test loss: 0.000771941862212085\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0007990699762573126\n",
      "Test loss: 0.0007288230108186897\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0007343337109020152\n",
      "Test loss: 0.0007829512071939746\n",
      "Train loss: 0.0006840729654594903\n",
      "Test loss: 0.0006687281932940776\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0006360923459864891\n",
      "Test loss: 0.0006757024578346462\n",
      "Train loss: 0.0005953992967868115\n",
      "Test loss: 0.0006445537225543682\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0005658177252392887\n"
     ]
    }
   ],
   "source": [
    "# Training Y- network\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "idxs = list(range(len(train_dataset)))\n",
    "random.shuffle(idxs)\n",
    "net_y = Net()\n",
    "net_y = net_y.to(device)\n",
    "optimizer = optim.Adam(net_y.parameters(), lr=0.0001)\n",
    "train_idxs = idxs[:int(len(train_dataset) * 0.8)]\n",
    "test_idxs = idxs[int(len(train_dataset) * 0.8):]\n",
    "min_loss = 1\n",
    "for epoch in range(10):\n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    for idx in test_idxs:\n",
    "        x = np.stack([train_dataset[idx]['image1'], train_dataset[idx]['image2']])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_y(x)\n",
    "        target = torch.tensor(train_dataset[idx]['rel_pose'][1]).float().to(device)\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        test_total += loss.item()\n",
    "    print(\"Test loss:\", test_total / len(test_idxs))\n",
    "    if min_loss > test_total / len(test_idxs):\n",
    "        print(\"New lowest test loss, saved!\")\n",
    "        torch.save(net_y, \"net_y_5.pyt\")\n",
    "        min_loss = test_total / len(test_idxs)\n",
    "    \n",
    "    for idx in train_idxs:\n",
    "        x = np.stack([train_dataset[idx]['image1'], train_dataset[idx]['image2']])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_y(x)\n",
    "        target = torch.tensor(train_dataset[idx]['rel_pose'][1]).float().to(device)\n",
    "        #criterion = nn.MSELoss()\n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        train_total += loss.item()\n",
    "        optimizer.step()     \n",
    "    print(\"Train loss:\", train_total / len(train_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0242aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09476261270518156\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.009953528699628567\n",
      "Test loss: 0.005525380642388258\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.004624983897714913\n",
      "Test loss: 0.004134728669148424\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0037004139556491367\n",
      "Test loss: 0.0035637545741653825\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0032126437207665773\n",
      "Test loss: 0.003060672995630258\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0028946787952134757\n",
      "Test loss: 0.0028743905745250127\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.002628279705770251\n",
      "Test loss: 0.0026294893421883727\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.002420206539654327\n",
      "Test loss: 0.002521162889597588\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0022744897735447528\n",
      "Test loss: 0.0024754295891904537\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0021391579403539744\n",
      "Test loss: 0.002340622510247319\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.002021595889916851\n"
     ]
    }
   ],
   "source": [
    "# Training Angle- network\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "idxs = list(range(len(train_dataset)))\n",
    "random.shuffle(idxs)\n",
    "net_angle = Net()\n",
    "net_angle = net_angle.to(device)\n",
    "optimizer = optim.Adam(net_angle.parameters(), lr=0.0001)\n",
    "train_idxs = idxs[:int(len(train_dataset) * 0.8)]\n",
    "test_idxs = idxs[int(len(train_dataset) * 0.8):]\n",
    "min_loss = 1\n",
    "for epoch in range(10):\n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    for idx in test_idxs:\n",
    "        x = np.stack([train_dataset[idx]['image1'], train_dataset[idx]['image2']])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_angle(x)\n",
    "        target = torch.tensor(train_dataset[idx]['rel_pose'][2]).float().to(device)\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        test_total += loss.item()\n",
    "    print(\"Test loss:\", test_total / len(test_idxs))\n",
    "    if min_loss > test_total / len(test_idxs):\n",
    "        print(\"New lowest test loss, saved!\")\n",
    "        torch.save(net_angle, \"net_angle_5.pyt\")\n",
    "        min_loss = test_total / len(test_idxs)\n",
    "    \n",
    "    for idx in train_idxs:\n",
    "        x = np.stack([train_dataset[idx]['image1'], train_dataset[idx]['image2']])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_angle(x)\n",
    "        target = torch.tensor(train_dataset[idx]['rel_pose'][2]).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        train_total += loss.item()\n",
    "        optimizer.step()     \n",
    "    print(\"Train loss:\", train_total / len(train_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce575ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
