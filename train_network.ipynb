{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb11994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas\n",
    "import math\n",
    "from generate_inputs import GenerateInputVector\n",
    "from generate_inputs import device\n",
    "from generate_inputs import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f3ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './data/traj_2/'\n",
    "pose_list, image_list, image1_list, image2_list, rel_pose_list = GenerateInputVector(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d400565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([])\n",
      "(1, 2, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "# Verifying input dimensions\n",
    "class Net(nn.Module):\n",
    "    #Architecture is LeNet modification\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(2, 16, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),)\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x[0][0]\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "\n",
    "input = torch.randn(1, 2, 224, 224).to(device)\n",
    "out = net(input)\n",
    "print(out.shape)\n",
    "\n",
    "x = np.stack([image1_list[0], image2_list[0]])\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e000c7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3836405336922534\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.05504012868248121\n",
      "Test loss: 0.14367590617445966\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.04047423058442282\n",
      "Test loss: 0.11223090778349254\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0379344704450135\n",
      "Test loss: 0.10816981263518946\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.03482230418491347\n",
      "Test loss: 0.1009101125731254\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.033453806534710695\n",
      "Test loss: 0.0818525785436576\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.02656361621487535\n",
      "Test loss: 0.08285717725819476\n",
      "Train loss: 0.022237277243989675\n",
      "Test loss: 0.08304237977250546\n",
      "Train loss: 0.018954284762006234\n",
      "Test loss: 0.09098473217469707\n",
      "Train loss: 0.017573184861990224\n",
      "Test loss: 0.07900265548966721\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.01639602768483461\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.optim as optim\n",
    "idxs = list(range(len(image1_list)))\n",
    "#random.shuffle(idxs)\n",
    "\n",
    "net_x = Net()\n",
    "net_x = net_x.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net_x.parameters(), lr=0.0001)\n",
    "\n",
    "#random.shuffle(idxs)\n",
    "train_idxs = idxs[:int(len(image1_list) * 0.8)]\n",
    "test_idxs = idxs[int(len(image1_list) * 0.8):]\n",
    "min_loss = 1\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    for idx in test_idxs:\n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().to(device)\n",
    "        out = net_x(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][0]).float().to(device)\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        test_total += loss.item()\n",
    "    print(\"Test loss:\", test_total / len(test_idxs))\n",
    "    if min_loss > test_total / len(test_idxs):\n",
    "        print(\"New lowest test loss, saved!\")\n",
    "        torch.save(net_x, \"net_x_2.pyt\")\n",
    "        min_loss = test_total / len(test_idxs)\n",
    "    for idx in train_idxs:\n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().to(device)\n",
    "        out = net_x(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][0]).float().to(device)\n",
    "        #print(out.shape, target.shape)\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_total += loss.item()\n",
    "        optimizer.step()     \n",
    "    print(\"Train loss:\", train_total / len(train_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8aa064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2539747405686388\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.2553569317493737\n",
      "Test loss: 0.2539747405686388\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_499971/2525532190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtrain_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_total\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training X- network\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "idxs = list(range(len(image1_list)))\n",
    "random.shuffle(idxs)\n",
    "net_x = Net()\n",
    "net_x = net_x.to(device)\n",
    "optimizer = optim.Adam(net_x.parameters(), lr=0.0001)\n",
    "train_idxs = idxs[:int(len(image1_list) * 0.8)]\n",
    "test_idxs = idxs[int(len(image1_list) * 0.8):]\n",
    "min_loss = 1\n",
    "for epoch in range(10):\n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    for idx in test_idxs:\n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().to(device)\n",
    "        out = net_x(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][0]).float().to(device)\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        test_total += loss.item()\n",
    "    print(\"Test loss:\", test_total / len(test_idxs))\n",
    "    if min_loss > test_total / len(test_idxs):\n",
    "        print(\"New lowest test loss, saved!\")\n",
    "        torch.save(net_x, \"net_x_2.pyt\")\n",
    "        min_loss = test_total / len(test_idxs)\n",
    "    \n",
    "    for idx in train_idxs:\n",
    "        \n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().to(device)\n",
    "        out = net_x(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][0]).float().to(device)\n",
    "        #print(out.shape, target.shape)\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_total += loss.item()\n",
    "        optimizer.step()     \n",
    "    print(\"Train loss:\", train_total / len(train_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf90104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snarasimhan/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.06934934796342554\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.06934462997396713\n",
      "Test loss: 0.056546016219212326\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.05649986668777784\n",
      "Test loss: 0.005142409493488073\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.005295995845778969\n",
      "Test loss: 0.056623167368603226\n",
      "Train loss: 0.0566025965206657\n",
      "Test loss: 0.04293317949532105\n",
      "Train loss: 0.042929369274511436\n",
      "Test loss: 0.00805713707449527\n",
      "Train loss: 0.008079838621347868\n",
      "Test loss: 0.028063110262018673\n",
      "Train loss: 0.028025350178265494\n",
      "Test loss: 0.03630810165415127\n",
      "Train loss: 0.03625017521397258\n",
      "Test loss: 0.02779315715049401\n",
      "Train loss: 0.027752790297349495\n",
      "Test loss: 0.011516068785599845\n",
      "Train loss: 0.011595740350759873\n"
     ]
    }
   ],
   "source": [
    "# Training Y- network\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "idxs = list(range(len(image1_list)))\n",
    "random.shuffle(idxs)\n",
    "net_y = Net()\n",
    "optimizer = optim.Adam(net_y.parameters(), lr=0.0001)\n",
    "train_idxs = idxs[:int(len(image1_list) * 0.8)]\n",
    "test_idxs = idxs[int(len(image1_list) * 0.8):]\n",
    "min_loss = 1\n",
    "for epoch in range(10):\n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    for idx in test_idxs:\n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_y(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][1]).float().cuda()\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        test_total += loss.item()\n",
    "    print(\"Test loss:\", test_total / len(test_idxs))\n",
    "    if min_loss > test_total / len(test_idxs):\n",
    "        print(\"New lowest test loss, saved!\")\n",
    "        torch.save(net_y, \"net_y_2.pyt\")\n",
    "        min_loss = test_total / len(test_idxs)\n",
    "    \n",
    "    for idx in train_idxs:\n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_y(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][1]).float().cuda()\n",
    "        #criterion = nn.MSELoss()\n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.L1Loss()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        train_total += loss.item()\n",
    "        optimizer.step()     \n",
    "    print(\"Train loss:\", train_total / len(train_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0242aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0018061496475784789\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0017800304391827136\n",
      "Test loss: 0.0045937059533164406\n",
      "Train loss: 0.004494457818568011\n",
      "Test loss: 0.0012841282956385603\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.001224031749492032\n",
      "Test loss: 0.001449465198994546\n",
      "Train loss: 0.0014238361287837323\n",
      "Test loss: 0.0015872785368824297\n",
      "Train loss: 0.0015678407576588272\n",
      "Test loss: 0.0012459499932667745\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0012187522431093111\n",
      "Test loss: 0.0009906131112756272\n",
      "New lowest test loss, saved!\n",
      "Train loss: 0.0009516366723274594\n",
      "Test loss: 0.0009798973948516134\n",
      "New lowest test loss, saved!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_490159/3484044362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtrain_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Angle- network\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "idxs = list(range(len(image1_list)))\n",
    "random.shuffle(idxs)\n",
    "net_angle = Net()\n",
    "optimizer = optim.Adam(net_angle.parameters(), lr=0.0001)\n",
    "train_idxs = idxs[:int(len(image1_list) * 0.8)]\n",
    "test_idxs = idxs[int(len(image1_list) * 0.8):]\n",
    "min_loss = 1\n",
    "for epoch in range(10):\n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    for idx in test_idxs:\n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_angle(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][2]).float().cuda()\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(out, target)\n",
    "        test_total += loss.item()\n",
    "    print(\"Test loss:\", test_total / len(test_idxs))\n",
    "    if min_loss > test_total / len(test_idxs):\n",
    "        print(\"New lowest test loss, saved!\")\n",
    "        torch.save(net_angle, \"net_angle_2.pyt\")\n",
    "        min_loss = test_total / len(test_idxs)\n",
    "    \n",
    "    for idx in train_idxs:\n",
    "        x = np.stack([image1_list[idx], image2_list[idx]])\n",
    "        x = torch.tensor(np.expand_dims(x, axis=0)).float().cuda()\n",
    "        out = net_angle(x)\n",
    "        target = torch.tensor(rel_pose_list[idx][2]).float().cuda()\n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        train_total += loss.item()\n",
    "        optimizer.step()     \n",
    "    print(\"Train loss:\", train_total / len(train_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce575ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
