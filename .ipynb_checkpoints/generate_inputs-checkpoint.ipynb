{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def Test():\n",
    "    print('test')\n",
    "#---------------------------------------------------------------------------------------------------------#\n",
    "# pose = [x(m), y(m), theta(rad)]\n",
    "def RelativePose(pose1, pose2):\n",
    "    c = np.cos(-pose1[2])\n",
    "    s = np.sin(-pose1[2])\n",
    "    x = pose2[0] - pose1[0]\n",
    "    y = pose2[1] - pose1[1]\n",
    "    Theta = pose2[2] - pose1[2]\n",
    "    X = c*x - s*y\n",
    "    Y = s*x + c*y\n",
    "    return np.array([X, Y, Theta])\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------#\n",
    "def AbsolutePose(pose1, relPose):\n",
    "    c = np.cos(pose1[2])\n",
    "    s = np.sin(pose1[2])\n",
    "    x = c*relPose[0] - s*relPose[1]\n",
    "    y = s*relPose[0] + c*relPose[1]\n",
    "    Theta = pose1[2] + relPose[2]\n",
    "    X = pose1[0] + x\n",
    "    Y = pose1[1] + y\n",
    "    return np.array([X, Y, Theta])\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------#\n",
    "def GenerateInputVector(traj_num_list):\n",
    "    max_succ_dist = 0.5\n",
    "    max_succ_ang = math.radians(10)\n",
    "    \n",
    "    image_list = []\n",
    "    image1_list = []\n",
    "    image2_list = []\n",
    "    rel_pose_list = []\n",
    "    \n",
    "    for k in traj_num_list:\n",
    "        dir = './data/traj_' + str(k) + '/'\n",
    "        print(dir)\n",
    "        pose_list = pandas.read_csv(dir + 'pose_list.csv', header=None).values\n",
    "        N = len(pose_list)\n",
    "        for i in range(0, N-1):\n",
    "            image_list.append(cv2.imread(dir + 'img_' + str(i) + '.jpg', 0)/255)\n",
    "            for j in range(i+1, N, 1):\n",
    "                rel_pose = RelativePose(pose_list[i], pose_list[j])\n",
    "                dist = np.sqrt(rel_pose[0]*rel_pose[0] + rel_pose[1]*rel_pose[1])\n",
    "                ang = rel_pose[2]\n",
    "                if dist < max_succ_dist and ang < max_succ_ang:\n",
    "                    image1_list.append(cv2.imread(dir + 'img_' + str(i) + '.jpg', 0)/255)\n",
    "                    image2_list.append(cv2.imread(dir + 'img_' + str(j) + '.jpg', 0)/255)\n",
    "                    rel_pose_list.append(rel_pose)\n",
    "        image_list.append(cv2.imread(dir + 'img_' + str(N-1) + '.jpg', 0)/255)\n",
    "    return pose_list, image_list, image1_list, image2_list, rel_pose_list\n",
    "\n",
    "        \n",
    "#---------------------------------------------------------------------------------------------------------#\n",
    "class TrajectoryDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, traj_num_list , max_num_pose, max_dis, max_ang):\n",
    "        idx_map = np.zeros(len(traj_num_list), dtype = int)\n",
    "        rel_pose_idx_map = []\n",
    "        rel_pose_map = []\n",
    "        l = 0\n",
    "        for k in traj_num_list:\n",
    "            dir = root_dir + 'traj_' + str(k) + '/'\n",
    "            print(k)\n",
    "\n",
    "            pose_list = pandas.read_csv(dir + 'pose_list.csv', header=None).values\n",
    "            N = len(pose_list)\n",
    "            rel_pose_idx_list = np.zeros(N-1, dtype = int)\n",
    "            rel_pose_list = []\n",
    "\n",
    "            for i in range(0, N-1):\n",
    "                num_poses = 0\n",
    "                for j in range(i+1, N, 1):\n",
    "                    rel_pose = RelativePose(pose_list[i], pose_list[j])\n",
    "                    dis = np.sqrt(rel_pose[0]*rel_pose[0] + rel_pose[1]*rel_pose[1])\n",
    "                    ang = rel_pose[2]\n",
    "\n",
    "                    if dis <= max_dis and ang <= max_ang and (j - i) <= max_num_pose:\n",
    "                        rel_pose_list.append(rel_pose)\n",
    "                        num_poses = num_poses + 1\n",
    "                    else:\n",
    "                        break      \n",
    "                rel_pose_idx_list[i] = num_poses\n",
    "            rel_pose_idx_list = np.cumsum(rel_pose_idx_list)\n",
    "            idx_map[l] = len(rel_pose_list)\n",
    "\n",
    "            if rel_pose_idx_list[-1] != idx_map[l]:\n",
    "                print('Error in TrajectoryDataset')\n",
    "            rel_pose_idx_map.append(rel_pose_idx_list)\n",
    "            rel_pose_map.append(rel_pose_list)\n",
    "            l = l + 1\n",
    "        idx_map = np.cumsum(idx_map)\n",
    "        \n",
    "        self.idx_map = idx_map\n",
    "        self.rel_pose_idx_map = rel_pose_idx_map\n",
    "        self.rel_pose_map = rel_pose_map\n",
    "        self.root_dir = root_dir\n",
    "        self.traj_num_list = traj_num_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.idx_map[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        if idx >= self.idx_map[-1] or idx < 0:\n",
    "            print('Larger than bound')\n",
    "\n",
    "        outer_idx = np.argmax(self.idx_map > idx)\n",
    "        if outer_idx > 0:\n",
    "            ij = idx - self.idx_map[outer_idx - 1]\n",
    "            inner_idx = np.argmax(self.rel_pose_idx_map[outer_idx] > ij)\n",
    "        else:\n",
    "            ij = idx\n",
    "            inner_idx = np.argmax(self.rel_pose_idx_map[outer_idx] > ij)\n",
    "\n",
    "        i = inner_idx\n",
    "        if i > 0:\n",
    "            j = ij - self.rel_pose_idx_map[outer_idx][i - 1] + i + 1\n",
    "        else:\n",
    "            j = ij + i + 1\n",
    "        \n",
    "        dir = self.root_dir + 'traj_' + str(self.traj_num_list[outer_idx]) + '/'\n",
    "        \n",
    "        image1 = cv2.imread(dir + 'img_' + str(i) + '.jpg', 0)/255\n",
    "        image2 = cv2.imread(dir + 'img_' + str(j) + '.jpg', 0)/255\n",
    "        rel_pose = self.rel_pose_map[outer_idx][ij]\n",
    "        \n",
    "        sample = {'image1': image1, 'image2': image2, 'rel_pose': rel_pose}\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------#\n",
    "class Net(nn.Module):\n",
    "    #Architecture is LeNet modification\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(2, 16, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),)\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
